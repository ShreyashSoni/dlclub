{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - 1\n",
    "In this project, we'll build a Neural Network with two hidden layers to classify the images of hand written digits in the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/neural_net.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lines of code which will download and read in the data automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `mnist` is a lightweight class which stores the training, validation, and testing sets as NumPy arrays. It also provides a function for iterating through data minibatches, which we will use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is importing TensorFlow and defining our session. TensorFlow, in a sense, creates a directed acyclic graph (flow chart) which you later feed with data and run in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set our hyperparameters. This is basically an iterative process and we experiment with different parameter values. We select the values depending on the final performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "model_path = \"/checkpoints/model.ckpt\"\n",
    "\n",
    "# network parameters\n",
    "# number of nodes in first hidden layer\n",
    "n_hidden_1 = 256\n",
    "# number of nodes in second hidden layer\n",
    "n_hidden_2 = 256\n",
    "\n",
    "n_input = 784 # MNIST data input (img shape: 28x28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start building the computation graph by creating nodes for the input images and target output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `x` and `y` aren't specific values. Rather, they are each a `placeholder` -- a value that we'll input when we ask TensorFlow to run a computation.\n",
    "\n",
    "The input images `x` will consist of a 2d tensor of floating point numbers. Here we assign it a shape of `[None, 784]`, where `784` is the dimensionality of a single flattened 28 by 28 pixel MNIST image, and `None` indicates that the first dimension, corresponding to the batch size, can be of any size. The target output classes `y` will also consist of a 2d tensor, where each row is a one-hot 10-dimensional vector indicating which digit class (zero through nine) the corresponding MNIST image belongs to.\n",
    "\n",
    "The `shape` argument to `placeholder` is optional, but it allows TensorFlow to automatically catch bugs stemming from inconsistent tensor shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the `weights` and `biases`. These two values are the grunt workers of the classifierâ€”they will be the only values we will need to calculate our prediction after the classifier is trained.\n",
    "We will set their initial values from a `random_normal` probability distribution and TensorFlow will optimize these values later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer weights and bias\n",
    "weights = {\n",
    "    'in_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h1_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h2_out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we define a function to create our neural network model. It takes in as parameters, the input images `x`, the `weights` and the `biases`.\n",
    "\n",
    "Here the function will cretae a network with two hidden layers.\n",
    "It will return the logits that we'll later feed into the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the model\n",
    "def neural_network(x, weights, biases):\n",
    "    # first hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['in_h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # second hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h1_h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # output layer with linear activation to get logits\n",
    "    output = tf.matmul(layer_2, weights['h2_out']) + biases['out']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print_stats` is a helper function to print some network stats during training.\n",
    "\n",
    "It will print out the `cost (error)` and `accuracy` of the network after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(epoch_i, sess, last_features, last_labels):\n",
    "    # print cost and validation accuracy of an epoch\n",
    "    current_cost = sess.run(cost,\n",
    "                           feed_dict={x: last_features, y: last_labels})\n",
    "    \n",
    "    valid_accuracy = sess.run(accuracy, \n",
    "                             feed_dict={x: valid_features, y: valid_labels})\n",
    "    \n",
    "    print('Epoch: {:<3} - Cost: {:<6.3} Valid Accuracy: {:<5.3}'.format(epoch_i, \n",
    "                                                                        current_cost, \n",
    "                                                                        valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we define our `cost` function and the `optimizer` we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-acaaae05d34e>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "predictions = neural_network(x, weights, biases)\n",
    "\n",
    "# define loss and the optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# saver operator to save all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   - Cost: 45.2   Valid Accuracy: 0.806\n",
      "Epoch: 1   - Cost: 55.5   Valid Accuracy: 0.854\n",
      "Epoch: 2   - Cost: 32.9   Valid Accuracy: 0.869\n",
      "Epoch: 3   - Cost: 27.9   Valid Accuracy: 0.877\n",
      "Epoch: 4   - Cost: 41.5   Valid Accuracy: 0.886\n",
      "Epoch: 5   - Cost: 36.3   Valid Accuracy: 0.89 \n",
      "Epoch: 6   - Cost: 19.7   Valid Accuracy: 0.887\n",
      "Epoch: 7   - Cost: 20.2   Valid Accuracy: 0.892\n",
      "Epoch: 8   - Cost: 15.0   Valid Accuracy: 0.898\n",
      "Epoch: 9   - Cost: 25.8   Valid Accuracy: 0.901\n",
      "\n",
      "Model saved in: /checkpoints/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize all the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training cycles\n",
    "    for epoch in range(epochs):\n",
    "        total_batches = int(mnist.train.num_examples/batch_size)\n",
    "        # loop over all the batches\n",
    "        for i in range(total_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # run optimizer\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        # display the stats\n",
    "        print_stats(epoch, sess, batch_x, batch_y)\n",
    "        \n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"\\nModel saved in: %s\" %save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /checkpoints/model.ckpt\n",
      "Model restored from: /checkpoints/model.ckpt\n",
      "\n",
      "Test Accuracy: 0.8952999711036682\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # restore the model weights from the saved model\n",
    "    load_path = saver.restore(sess, model_path)\n",
    "    print(\"Model restored from: %s\" %save_path)\n",
    "    \n",
    "    # calculate the final test accuracy\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={x: test_features,\n",
    "                                                 y: test_labels})\n",
    "    \n",
    "    print('\\nTest Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
